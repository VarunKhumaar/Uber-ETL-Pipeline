# Uber End-to-End Data Engineering Project using Airflow and Python
Used - GCP Storage, Google Colab, Python, AWS EC2, Airflow workflow orchestration, AWS S3, and Tableau

![image](https://github.com/VarunKhumaar/Uber-ETL-Pipeline/assets/67249540/d8971fe9-a17b-462f-9bca-823ea9377e3e)



- Extracted the data from GCP Cloud Storage
- Used Python to perform transformations
- Deployed the code on Airflow/AWS EC2 #workflow orchestration
- Loaded the transformed data on Amazon S3 bucket
- Connected the AWS S3 bucket to Tableau



Final Tableau Dashboard: [link](https://public.tableau.com/app/profile/varunkhumaar)
![Screenshot (71)](https://github.com/VarunKhumaar/Uber-ETL-Pipeline/assets/67249540/5e2eefe1-d231-492b-8bda-329128ee4135)

Ideas/Inspiration from:
- Twitter Data Pipeline using Airflow for Beginners: https://www.youtube.com/watch?v=q8q3OFFfY6c
- Uber Data Analytics: https://www.youtube.com/watch?v=WpQECq5Hx9g
